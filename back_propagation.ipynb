{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播\n",
    "\n",
    "---\n",
    "\n",
    "[反向传播神经网络极简入门](http://www.hankcs.com/ml/back-propagation-neural-network.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Sigmoid\n",
    "\n",
    "$ f(x) = \\frac{ 1 }{1 + e ^ x} $\n",
    "\n",
    "$ f^`(x) = f(x)(1 - f(x)$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    sigmoid 函数，1/(1+e^-x)\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return 1.0/1.0 + math.exp(-x)\n",
    "\n",
    "def dsigmoid(y):\n",
    "    \"\"\"\n",
    "    sigmoid 函数的导数\n",
    "    :param y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Tanh\n",
    "\n",
    "$ f(x) = \\frac{1 - e^\\left(-x \\right)}{1 + e^\\left(-x \\right)} $\n",
    "\n",
    "$ f^`(x) = 1 - \\left( f(x) \\right)^2$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    \"\"\"\n",
    "    sigmoid 函数，tanh \n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return math.tanh(x)\n",
    "\n",
    "def dtanh(y):\n",
    "    \"\"\"\n",
    "    sigmoid 函数的导数\n",
    "    :param y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return 1 - y ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNN(self, inputs):\n",
    "        \"\"\"\n",
    "        前向传播进行分类\n",
    "        :param inputs:输入\n",
    "        :return:类别\n",
    "        \"\"\"\n",
    "        if len(inputs) != self.ni - 1:\n",
    "            print('incorrect number of inputs')\n",
    " \n",
    "        for i in range(self.ni - 1):\n",
    "            self.ai[i] = inputs[i]\n",
    " \n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum += ( self.ai[i] * self.wi[i][j] )\n",
    "            self.ah[j] = sigmoid(sum)\n",
    " \n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum += ( self.ah[j] * self.wo[j][k] )\n",
    "            self.ao[k] = sigmoid(sum)\n",
    " \n",
    "        return self.ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagate(self, targets, N, M):\n",
    "        \"\"\"\n",
    "        后向传播算法\n",
    "        :param targets: 实例的类别 \n",
    "        :param N: 本次学习率\n",
    "        :param M: 上次学习率\n",
    "        :return: 最终的误差平方和的一半\n",
    "        \"\"\"\n",
    "        # http://www.youtube.com/watch?v=aVId8KMsdUU&feature=BFa&list=LLldMCkmXl4j9_v0HeKdNcRA\n",
    " \n",
    "        # 计算输出层 deltas\n",
    "        # dE/dw[j][k] = (t[k] - ao[k]) * s'( SUM( w[j][k]*ah[j] ) ) * ah[j]\n",
    "        output_deltas = [0.0] * self.no\n",
    "        for k in range(self.no):\n",
    "            error = targets[k] - self.ao[k]\n",
    "            output_deltas[k] = error * dsigmoid(self.ao[k])\n",
    " \n",
    "        # 更新输出层权值\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                # output_deltas[k] * self.ah[j] 才是 dError/dweight[j][k]\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] += N * change + M * self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    " \n",
    "        # 计算隐藏层 deltas\n",
    "        hidden_deltas = [0.0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error += output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = error * dsigmoid(self.ah[j])\n",
    " \n",
    "        # 更新输入层权值\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j] * self.ai[i]\n",
    "                # print 'activation',self.ai[i],'synapse',i,j,'change',change\n",
    "                self.wi[i][j] += N * change + M * self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    " \n",
    "        # 计算误差平方和\n",
    "        # 1/2 是为了好看，**2 是平方\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error = 0.5 * (targets[k] - self.ao[k]) ** 2\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
