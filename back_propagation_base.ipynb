{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通俗理解神经网络BP传播算法\n",
    "\n",
    "[通俗理解神经网络BP传播算法](https://zhuanlan.zhihu.com/p/24801814)\n",
    "\n",
    "---\n",
    "\n",
    "## BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original  [[ 0.1  0.8]\n",
      " [ 0.4  0.6]] \n",
      " [[ 0.3  0.9]]\n",
      "Iter [ 0 ] Error: [[ 0.0181039]]\n",
      "l2_delta= [[-0.04068113]]\n",
      "[[ 0.09661944  0.78985831]\n",
      " [ 0.39661944  0.58985831]] \n",
      " [[ 0.27232597  0.87299836]]\n",
      "Iter [ 1 ] Error: [[ 0.01652628]]\n",
      "l2_delta= [[-0.03944183]]\n",
      "[[ 0.09363393  0.78028763]\n",
      " [ 0.39363393  0.58028763]] \n",
      " [[ 0.2455836   0.84691021]]\n",
      "Iter [ 2 ] Error: [[ 0.01506159]]\n",
      "l2_delta= [[-0.03816188]]\n",
      "[[ 0.09102066  0.7712756 ]\n",
      " [ 0.39102066  0.5712756 ]] \n",
      " [[ 0.21978966  0.82175133]]\n",
      "Iter [ 3 ] Error: [[ 0.0137064]]\n",
      "l2_delta= [[-0.03685334]]\n",
      "[[ 0.08875541  0.76280627]\n",
      " [ 0.38875541  0.56280627]] \n",
      " [[ 0.19495316  0.79752995]]\n",
      "Iter [ 4 ] Error: [[ 0.01245646]]\n",
      "l2_delta= [[-0.03552736]]\n",
      "[[ 0.08681317  0.75486083]\n",
      " [ 0.38681317  0.55486083]] \n",
      " [[ 0.17107608  0.7742475 ]]\n",
      "Iter [ 5 ] Error: [[ 0.01130686]]\n",
      "l2_delta= [[-0.03419403]]\n",
      "[[ 0.08516869  0.74741831]\n",
      " [ 0.38516869  0.54741831]] \n",
      " [[ 0.14815418  0.75189938]]\n",
      "Iter [ 6 ] Error: [[ 0.01025225]]\n",
      "l2_delta= [[-0.03286237]]\n",
      "[[ 0.08379687  0.74045618]\n",
      " [ 0.38379687  0.54045618]] \n",
      " [[ 0.12617784  0.73047577]]\n",
      "Iter [ 7 ] Error: [[ 0.00928702]]\n",
      "l2_delta= [[-0.03154026]]\n",
      "[[ 0.08267319  0.73395087]\n",
      " [ 0.38267319  0.53395087]] \n",
      " [[ 0.10513284  0.70996241]]\n",
      "Iter [ 8 ] Error: [[ 0.00840541]]\n",
      "l2_delta= [[-0.0302345]]\n",
      "[[ 0.08177395  0.72787829]\n",
      " [ 0.38177395  0.52787829]] \n",
      " [[ 0.08500109  0.69034129]]\n",
      "Iter [ 9 ] Error: [[ 0.00760166]]\n",
      "l2_delta= [[-0.02895084]]\n",
      "[[ 0.08107654  0.72221424]\n",
      " [ 0.38107654  0.52221424]] \n",
      " [[ 0.06576133  0.67159137]]\n",
      "Iter [ 10 ] Error: [[ 0.0068701]]\n",
      "l2_delta= [[-0.02769404]]\n",
      "[[ 0.08055957  0.71693468]\n",
      " [ 0.38055957  0.51693468]] \n",
      " [[ 0.0473898  0.6536892]]\n",
      "Iter [ 11 ] Error: [[ 0.00620521]]\n",
      "l2_delta= [[-0.02646798]]\n",
      "[[ 0.08020299  0.71201606]\n",
      " [ 0.38020299  0.51201606]] \n",
      " [[ 0.02986079  0.63660945]]\n",
      "Iter [ 12 ] Error: [[ 0.00560171]]\n",
      "l2_delta= [[-0.02527572]]\n",
      "[[ 0.07998813  0.7074355 ]\n",
      " [ 0.37998813  0.5074355 ]] \n",
      " [[ 0.01314714  0.62032541]]\n",
      "Iter [ 13 ] Error: [[ 0.00505455]]\n",
      "l2_delta= [[-0.0241196]]\n",
      "[[ 0.07989775  0.70317096]\n",
      " [ 0.37989775  0.50317096]] \n",
      " [[-0.00277934  0.60480943]]\n",
      "Iter [ 14 ] Error: [[ 0.00455898]]\n",
      "l2_delta= [[-0.02300134]]\n",
      "[[ 0.07991599  0.69920132]\n",
      " [ 0.37991599  0.49920132]] \n",
      " [[-0.01794744  0.59003325]]\n",
      "Iter [ 15 ] Error: [[ 0.00411052]]\n",
      "l2_delta= [[-0.02192209]]\n",
      "[[ 0.08002838  0.69550651]\n",
      " [ 0.38002838  0.49550651]] \n",
      " [[-0.03238627  0.57596835]]\n",
      "Iter [ 16 ] Error: [[ 0.00370503]]\n",
      "l2_delta= [[-0.02088254]]\n",
      "[[ 0.08022175  0.69206751]\n",
      " [ 0.38022175  0.49206751]] \n",
      " [[-0.04612497  0.56258621]]\n",
      "Iter [ 17 ] Error: [[ 0.00333862]]\n",
      "l2_delta= [[-0.01988298]]\n",
      "[[ 0.0804842   0.68886638]\n",
      " [ 0.3804842   0.48886638]] \n",
      " [[-0.0591925   0.54985847]]\n",
      "Iter [ 18 ] Error: [[ 0.00300775]]\n",
      "l2_delta= [[-0.01892334]]\n",
      "[[ 0.08080501  0.68588628]\n",
      " [ 0.38080501  0.48588628]] \n",
      " [[-0.07161744  0.53775719]]\n",
      "Iter [ 19 ] Error: [[ 0.00270911]]\n",
      "l2_delta= [[-0.01800331]]\n",
      "[[ 0.08117456  0.68311142]\n",
      " [ 0.38117456  0.48311142]] \n",
      " [[-0.08342786  0.52625493]]\n",
      "Iter [ 20 ] Error: [[ 0.00243969]]\n",
      "l2_delta= [[-0.01712231]]\n",
      "[[ 0.08158427  0.68052704]\n",
      " [ 0.38158427  0.48052704]] \n",
      " [[-0.09465118  0.5153249 ]]\n",
      "Iter [ 21 ] Error: [[ 0.00219674]]\n",
      "l2_delta= [[-0.01627961]]\n",
      "[[ 0.08202649  0.67811939]\n",
      " [ 0.38202649  0.47811939]] \n",
      " [[-0.10531409  0.50494101]]\n",
      "Iter [ 22 ] Error: [[ 0.00197772]]\n",
      "l2_delta= [[-0.01547431]]\n",
      "[[ 0.08249446  0.67587566]\n",
      " [ 0.38249446  0.47587566]] \n",
      " [[-0.11544251  0.49507797]]\n",
      "Iter [ 23 ] Error: [[ 0.00178034]]\n",
      "l2_delta= [[-0.0147054]]\n",
      "[[ 0.0829822   0.67378398]\n",
      " [ 0.3829822   0.47378398]] \n",
      " [[-0.12506148  0.48571133]]\n",
      "Iter [ 24 ] Error: [[ 0.00160251]]\n",
      "l2_delta= [[-0.01397179]]\n",
      "[[ 0.08348446  0.67183329]\n",
      " [ 0.38348446  0.47183329]] \n",
      " [[-0.13419517  0.4768175 ]]\n",
      "Iter [ 25 ] Error: [[ 0.00144233]]\n",
      "l2_delta= [[-0.01327233]]\n",
      "[[ 0.08399666  0.67001338]\n",
      " [ 0.38399666  0.47001338]] \n",
      " [[-0.14286687  0.46837376]]\n",
      "Iter [ 26 ] Error: [[ 0.00129808]]\n",
      "l2_delta= [[-0.01260584]]\n",
      "[[ 0.08451478  0.66831478]\n",
      " [ 0.38451478  0.46831478]] \n",
      " [[-0.15109893  0.4603583 ]]\n",
      "Iter [ 27 ] Error: [[ 0.00116819]]\n",
      "l2_delta= [[-0.01197107]]\n",
      "[[ 0.08503536  0.66672871]\n",
      " [ 0.38503536  0.46672871]] \n",
      " [[-0.15891282  0.45275019]]\n",
      "Iter [ 28 ] Error: [[ 0.00105124]]\n",
      "l2_delta= [[-0.01136682]]\n",
      "[[ 0.0855554   0.66524707]\n",
      " [ 0.3855554   0.46524707]] \n",
      " [[-0.16632908  0.44552938]]\n",
      "Iter [ 29 ] Error: [[ 0.00094598]]\n",
      "l2_delta= [[-0.01079185]]\n",
      "[[ 0.08607235  0.66386237]\n",
      " [ 0.38607235  0.46386237]] \n",
      " [[-0.17336739  0.43867671]]\n",
      "Iter [ 30 ] Error: [[ 0.00085122]]\n",
      "l2_delta= [[-0.01024494]]\n",
      "[[ 0.08658402  0.66256767]\n",
      " [ 0.38658402  0.46256767]] \n",
      " [[-0.18004653  0.43217385]]\n",
      "Iter [ 31 ] Error: [[ 0.00076595]]\n",
      "l2_delta= [[-0.00972489]]\n",
      "[[ 0.08708857  0.66135658]\n",
      " [ 0.38708857  0.46135658]] \n",
      " [[-0.18638445  0.4260033 ]]\n",
      "Iter [ 32 ] Error: [[ 0.0006892]]\n",
      "l2_delta= [[-0.00923053]]\n",
      "[[ 0.08758446  0.66022318]\n",
      " [ 0.38758446  0.46022318]] \n",
      " [[-0.19239827  0.42014839]]\n",
      "Iter [ 33 ] Error: [[ 0.00062014]]\n",
      "l2_delta= [[-0.0087607]]\n",
      "[[ 0.0880704   0.65916201]\n",
      " [ 0.3880704   0.45916201]] \n",
      " [[-0.19810431  0.41459322]]\n",
      "Iter [ 34 ] Error: [[ 0.00055799]]\n",
      "l2_delta= [[-0.00831429]]\n",
      "[[ 0.08854536  0.65816801]\n",
      " [ 0.38854536  0.45816801]] \n",
      " [[-0.20351811  0.40932262]]\n",
      "Iter [ 35 ] Error: [[ 0.00050207]]\n",
      "l2_delta= [[-0.00789022]]\n",
      "[[ 0.08900851  0.65723651]\n",
      " [ 0.38900851  0.45723651]] \n",
      " [[-0.20865447  0.40432219]]\n",
      "Iter [ 36 ] Error: [[ 0.00045175]]\n",
      "l2_delta= [[-0.00748743]]\n",
      "[[ 0.08945919  0.65636319]\n",
      " [ 0.38945919  0.45636319]] \n",
      " [[-0.21352747  0.3995782 ]]\n",
      "Iter [ 37 ] Error: [[ 0.00040648]]\n",
      "l2_delta= [[-0.00710493]]\n",
      "[[ 0.08989691  0.65554408]\n",
      " [ 0.38989691  0.45554408]] \n",
      " [[-0.21815052  0.3950776 ]]\n",
      "Iter [ 38 ] Error: [[ 0.00036574]]\n",
      "l2_delta= [[-0.00674173]]\n",
      "[[ 0.09032132  0.65477546]\n",
      " [ 0.39032132  0.45477546]] \n",
      " [[-0.22253635  0.39080798]]\n",
      "Iter [ 39 ] Error: [[ 0.00032909]]\n",
      "l2_delta= [[-0.00639691]]\n",
      "[[ 0.09073218  0.65405394]\n",
      " [ 0.39073218  0.45405394]] \n",
      " [[-0.22669706  0.38675754]]\n",
      "Iter [ 40 ] Error: [[ 0.00029612]]\n",
      "l2_delta= [[-0.00606957]]\n",
      "[[ 0.09112935  0.65337633]\n",
      " [ 0.39112935  0.45337633]] \n",
      " [[-0.23064416  0.38291509]]\n",
      "Iter [ 41 ] Error: [[ 0.00026645]]\n",
      "l2_delta= [[-0.00575885]]\n",
      "[[ 0.09151281  0.65273972]\n",
      " [ 0.39151281  0.45273972]] \n",
      " [[-0.23438858  0.37926997]]\n",
      "Iter [ 42 ] Error: [[ 0.00023976]]\n",
      "l2_delta= [[-0.00546393]]\n",
      "[[ 0.09188258  0.65214139]\n",
      " [ 0.39188258  0.45214139]] \n",
      " [[-0.23794071  0.37581208]]\n",
      "Iter [ 43 ] Error: [[ 0.00021574]]\n",
      "l2_delta= [[-0.00518403]]\n",
      "[[ 0.09223876  0.65157882]\n",
      " [ 0.39223876  0.45157882]] \n",
      " [[-0.24131038  0.37253182]]\n",
      "Iter [ 44 ] Error: [[ 0.00019413]]\n",
      "l2_delta= [[-0.00491841]]\n",
      "[[ 0.09258152  0.65104968]\n",
      " [ 0.39258152  0.45104968]] \n",
      " [[-0.24450697  0.36942008]]\n",
      "Iter [ 45 ] Error: [[ 0.00017469]]\n",
      "l2_delta= [[-0.00466634]]\n",
      "[[ 0.09291104  0.6505518 ]\n",
      " [ 0.39291104  0.4505518 ]] \n",
      " [[-0.24753936  0.36646819]]\n",
      "Iter [ 46 ] Error: [[ 0.00015719]]\n",
      "l2_delta= [[-0.00442714]]\n",
      "[[ 0.09322759  0.65008317]\n",
      " [ 0.39322759  0.45008317]] \n",
      " [[-0.25041597  0.36366797]]\n",
      "Iter [ 47 ] Error: [[ 0.00014145]]\n",
      "l2_delta= [[-0.00420017]]\n",
      "[[ 0.09353142  0.64964193]\n",
      " [ 0.39353142  0.44964193]] \n",
      " [[-0.2531448  0.3610116]]\n",
      "Iter [ 48 ] Error: [[ 0.00012729]]\n",
      "l2_delta= [[-0.00398482]]\n",
      "[[ 0.09382284  0.64922634]\n",
      " [ 0.39382284  0.44922634]] \n",
      " [[-0.25573346  0.35849171]]\n",
      "Iter [ 49 ] Error: [[ 0.00011455]]\n",
      "l2_delta= [[-0.00378049]]\n",
      "[[ 0.09410216  0.64883478]\n",
      " [ 0.39410216  0.44883478]] \n",
      " [[-0.25818915  0.35610127]]\n",
      "Iter [ 50 ] Error: [[ 0.00010308]]\n",
      "l2_delta= [[-0.00358661]]\n",
      "[[ 0.09436972  0.64846576]\n",
      " [ 0.39436972  0.44846576]] \n",
      " [[-0.26051869  0.35383363]]\n",
      "Iter [ 51 ] Error: [[  9.27632745e-05]]\n",
      "l2_delta= [[-0.00340268]]\n",
      "[[ 0.09462587  0.64811786]\n",
      " [ 0.39462587  0.44811786]] \n",
      " [[-0.26272858  0.35168247]]\n",
      "Iter [ 52 ] Error: [[  8.34798028e-05]]\n",
      "l2_delta= [[-0.00322816]]\n",
      "[[ 0.09487095  0.64778979]\n",
      " [ 0.39487095  0.44778979]] \n",
      " [[-0.26482496  0.3496418 ]]\n",
      "Iter [ 53 ] Error: [[  7.51262967e-05]]\n",
      "l2_delta= [[-0.0030626]]\n",
      "[[ 0.09510534  0.64748034]\n",
      " [ 0.39510534  0.44748034]] \n",
      " [[-0.26681368  0.34770595]]\n",
      "Iter [ 54 ] Error: [[  6.76094923e-05]]\n",
      "l2_delta= [[-0.00290552]]\n",
      "[[ 0.09532938  0.64718837]\n",
      " [ 0.39532938  0.44718837]] \n",
      " [[-0.26870027  0.34586952]]\n",
      "Iter [ 55 ] Error: [[  6.08454893e-05]]\n",
      "l2_delta= [[-0.0027565]]\n",
      "[[ 0.09554345  0.64691282]\n",
      " [ 0.39554345  0.44691282]] \n",
      " [[-0.27048999  0.34412739]]\n",
      "Iter [ 56 ] Error: [[  5.47588101e-05]]\n",
      "l2_delta= [[-0.00261512]]\n",
      "[[ 0.0957479   0.64665271]\n",
      " [ 0.3957479   0.44665271]] \n",
      " [[-0.27218781  0.34247472]]\n",
      "Iter [ 57 ] Error: [[  4.92815538e-05]]\n",
      "l2_delta= [[-0.002481]]\n",
      "[[ 0.09594309  0.64640712]\n",
      " [ 0.39594309  0.44640712]] \n",
      " [[-0.27379845  0.34090691]]\n",
      "Iter [ 58 ] Error: [[  4.43526347e-05]]\n",
      "l2_delta= [[-0.00235375]]\n",
      "[[ 0.09612937  0.64617518]\n",
      " [ 0.39612937  0.44617518]] \n",
      " [[-0.27532641  0.33941959]]\n",
      "Iter [ 59 ] Error: [[  3.99170980e-05]]\n",
      "l2_delta= [[-0.00223304]]\n",
      "[[ 0.0963071   0.64595608]\n",
      " [ 0.3963071   0.44595608]] \n",
      " [[-0.27677594  0.33800863]]\n",
      "Iter [ 60 ] Error: [[  3.59255034e-05]]\n",
      "l2_delta= [[-0.00211852]]\n",
      "[[ 0.0964766   0.64574908]\n",
      " [ 0.3964766   0.44574908]] \n",
      " [[-0.27815106  0.33667009]]\n",
      "Iter [ 61 ] Error: [[  3.23333711e-05]]\n",
      "l2_delta= [[-0.00200987]]\n",
      "[[ 0.09663821  0.64555346]\n",
      " [ 0.39663821  0.44555346]] \n",
      " [[-0.2794556   0.33540026]]\n",
      "Iter [ 62 ] Error: [[  2.91006835e-05]]\n",
      "l2_delta= [[-0.0019068]]\n",
      "[[ 0.09679226  0.64536857]\n",
      " [ 0.39679226  0.44536857]] \n",
      " [[-0.28069319  0.3341956 ]]\n",
      "Iter [ 63 ] Error: [[  2.61914370e-05]]\n",
      "l2_delta= [[-0.00180902]]\n",
      "[[ 0.09693907  0.64519379]\n",
      " [ 0.39693907  0.44519379]] \n",
      " [[-0.28186727  0.33305276]]\n",
      "Iter [ 64 ] Error: [[  2.35732389e-05]]\n",
      "l2_delta= [[-0.00171626]]\n",
      "[[ 0.09707893  0.64502853]\n",
      " [ 0.39707893  0.44502853]] \n",
      " [[-0.2829811   0.33196856]]\n",
      "Iter [ 65 ] Error: [[  2.12169445e-05]]\n",
      "l2_delta= [[-0.00162826]]\n",
      "[[ 0.09721215  0.64487225]\n",
      " [ 0.39721215  0.44487225]] \n",
      " [[-0.28403779  0.33094   ]]\n",
      "Iter [ 66 ] Error: [[  1.90963310e-05]]\n",
      "l2_delta= [[-0.00154477]]\n",
      "[[ 0.09733901  0.64472444]\n",
      " [ 0.39733901  0.44472444]] \n",
      " [[-0.28504026  0.3299642 ]]\n",
      "Iter [ 67 ] Error: [[  1.71878044e-05]]\n",
      "l2_delta= [[-0.00146557]]\n",
      "[[ 0.0974598   0.64458462]\n",
      " [ 0.3974598   0.44458462]] \n",
      " [[-0.2859913   0.32903847]]\n",
      "Iter [ 68 ] Error: [[  1.54701353e-05]]\n",
      "l2_delta= [[-0.00139043]]\n",
      "[[ 0.09757477  0.64445233]\n",
      " [ 0.39757477  0.44445233]] \n",
      " [[-0.28689356  0.32816023]]\n",
      "Iter [ 69 ] Error: [[  1.39242217e-05]]\n",
      "l2_delta= [[-0.00131914]]\n",
      "[[ 0.0976842   0.64432716]\n",
      " [ 0.3976842   0.44432716]] \n",
      " [[-0.28774954  0.32732704]]\n",
      "Iter [ 70 ] Error: [[  1.25328756e-05]]\n",
      "l2_delta= [[-0.00125152]]\n",
      "[[ 0.09778834  0.64420871]\n",
      " [ 0.39778834  0.44420871]] \n",
      " [[-0.28856161  0.32653658]]\n",
      "Iter [ 71 ] Error: [[  1.12806307e-05]]\n",
      "l2_delta= [[-0.00118736]]\n",
      "[[ 0.09788741  0.64409659]\n",
      " [ 0.39788741  0.44409659]] \n",
      " [[-0.28933204  0.32578666]]\n",
      "Iter [ 72 ] Error: [[  1.01535701e-05]]\n",
      "l2_delta= [[-0.00112649]]\n",
      "[[ 0.09798166  0.64399047]\n",
      " [ 0.39798166  0.44399047]] \n",
      " [[-0.29006295  0.32507521]]\n",
      "Iter [ 73 ] Error: [[  9.13917040e-06]]\n",
      "l2_delta= [[-0.00106875]]\n",
      "[[ 0.0980713  0.64389  ]\n",
      " [ 0.3980713  0.44389  ]] \n",
      " [[-0.29075639  0.32440023]]\n",
      "Iter [ 74 ] Error: [[  8.22616248e-06]]\n",
      "l2_delta= [[-0.00101397]]\n",
      "[[ 0.09815656  0.64379488]\n",
      " [ 0.39815656  0.44379488]] \n",
      " [[-0.29141427  0.32375987]]\n",
      "Iter [ 75 ] Error: [[  7.40440534e-06]]\n",
      "l2_delta= [[-0.000962]]\n",
      "[[ 0.09823763  0.64370482]\n",
      " [ 0.39823763  0.44370482]] \n",
      " [[-0.29203841  0.32315234]]\n",
      "Iter [ 76 ] Error: [[  6.66477319e-06]]\n",
      "l2_delta= [[-0.00091269]]\n",
      "[[ 0.09831471  0.64361953]\n",
      " [ 0.39831471  0.44361953]] \n",
      " [[-0.29263055  0.32257597]]\n",
      "Iter [ 77 ] Error: [[  5.99905368e-06]]\n",
      "l2_delta= [[-0.00086592]]\n",
      "[[ 0.09838799  0.64353875]\n",
      " [ 0.39838799  0.44353875]] \n",
      " [[-0.29319234  0.32202914]]\n",
      "Iter [ 78 ] Error: [[  5.39985637e-06]]\n",
      "l2_delta= [[-0.00082154]]\n",
      "[[ 0.09845764  0.64346224]\n",
      " [ 0.39845764  0.44346224]] \n",
      " [[-0.29372533  0.32151034]]\n",
      "Iter [ 79 ] Error: [[  4.86053034e-06]]\n",
      "l2_delta= [[-0.00077944]]\n",
      "[[ 0.09852385  0.64338977]\n",
      " [ 0.39852385  0.44338977]] \n",
      " [[-0.29423099  0.32101815]]\n",
      "Iter [ 80 ] Error: [[  4.37509018e-06]]\n",
      "l2_delta= [[-0.00073949]]\n",
      "[[ 0.09858678  0.64332111]\n",
      " [ 0.39858678  0.44332111]] \n",
      " [[-0.29471073  0.32055118]]\n",
      "Iter [ 81 ] Error: [[  3.93814926e-06]]\n",
      "l2_delta= [[-0.0007016]]\n",
      "[[ 0.09864658  0.64325607]\n",
      " [ 0.39864658  0.44325607]] \n",
      " [[-0.29516588  0.32010815]]\n",
      "Iter [ 82 ] Error: [[  3.54485980e-06]]\n",
      "l2_delta= [[-0.00066564]]\n",
      "[[ 0.0987034   0.64319445]\n",
      " [ 0.3987034   0.44319445]] \n",
      " [[-0.29559771  0.31968782]]\n",
      "Iter [ 83 ] Error: [[  3.19085892e-06]]\n",
      "l2_delta= [[-0.00063154]]\n",
      "[[ 0.09875739  0.64313606]\n",
      " [ 0.39875739  0.44313606]] \n",
      " [[-0.2960074   0.31928904]]\n",
      "Iter [ 84 ] Error: [[  2.87222006e-06]]\n",
      "l2_delta= [[-0.00059918]]\n",
      "[[ 0.09880868  0.64308073]\n",
      " [ 0.39880868  0.44308073]] \n",
      " [[-0.29639609  0.3189107 ]]\n",
      "Iter [ 85 ] Error: [[  2.58540935e-06]]\n",
      "l2_delta= [[-0.00056847]]\n",
      "[[ 0.09885741  0.6430283 ]\n",
      " [ 0.39885741  0.4430283 ]] \n",
      " [[-0.29676486  0.31855175]]\n",
      "Iter [ 86 ] Error: [[  2.32724628e-06]]\n",
      "l2_delta= [[-0.00053935]]\n",
      "[[ 0.0989037   0.64297861]\n",
      " [ 0.3989037   0.44297861]] \n",
      " [[-0.29711474  0.31821119]]\n",
      "Iter [ 87 ] Error: [[  2.09486834e-06]]\n",
      "l2_delta= [[-0.00051171]]\n",
      "[[ 0.09894768  0.64293151]\n",
      " [ 0.39894768  0.44293151]] \n",
      " [[-0.29744668  0.31788809]]\n",
      "Iter [ 88 ] Error: [[  1.88569918e-06]]\n",
      "l2_delta= [[-0.00048549]]\n",
      "[[ 0.09898944  0.64288688]\n",
      " [ 0.39898944  0.44288688]] \n",
      " [[-0.29776161  0.31758154]]\n",
      "Iter [ 89 ] Error: [[  1.69742002e-06]]\n",
      "l2_delta= [[-0.00046062]]\n",
      "[[ 0.09902911  0.64284457]\n",
      " [ 0.39902911  0.44284457]] \n",
      " [[-0.29806041  0.31729071]]\n",
      "Iter [ 90 ] Error: [[  1.52794387e-06]]\n",
      "l2_delta= [[-0.00043702]]\n",
      "[[ 0.09906678  0.64280446]\n",
      " [ 0.39906678  0.44280446]] \n",
      " [[-0.2983439   0.31701477]]\n",
      "Iter [ 91 ] Error: [[  1.37539232e-06]]\n",
      "l2_delta= [[-0.00041463]]\n",
      "[[ 0.09910256  0.64276645]\n",
      " [ 0.39910256  0.44276645]] \n",
      " [[-0.29861286  0.31675297]]\n",
      "Iter [ 92 ] Error: [[  1.23807471e-06]]\n",
      "l2_delta= [[-0.00039339]]\n",
      "[[ 0.09913654  0.64273041]\n",
      " [ 0.39913654  0.44273041]] \n",
      " [[-0.29886803  0.31650459]]\n",
      "Iter [ 93 ] Error: [[  1.11446931e-06]]\n",
      "l2_delta= [[-0.00037324]]\n",
      "[[ 0.0991688   0.64269624]\n",
      " [ 0.3991688   0.44269624]] \n",
      " [[-0.29911014  0.31626894]]\n",
      "Iter [ 94 ] Error: [[  1.00320650e-06]]\n",
      "l2_delta= [[-0.00035412]]\n",
      "[[ 0.09919944  0.64266385]\n",
      " [ 0.39919944  0.44266385]] \n",
      " [[-0.29933984  0.31604536]]\n",
      "Iter [ 95 ] Error: [[  9.03053486e-07]]\n",
      "l2_delta= [[-0.00033598]]\n",
      "[[ 0.09922853  0.64263314]\n",
      " [ 0.39922853  0.44263314]] \n",
      " [[-0.29955777  0.31583323]]\n",
      "Iter [ 96 ] Error: [[  8.12900662e-07]]\n",
      "l2_delta= [[-0.00031877]]\n",
      "[[ 0.09925614  0.64260402]\n",
      " [ 0.39925614  0.44260402]] \n",
      " [[-0.29976454  0.31563197]]\n",
      "Iter [ 97 ] Error: [[  7.31749283e-07]]\n",
      "l2_delta= [[-0.00030244]]\n",
      "[[ 0.09928237  0.64257641]\n",
      " [ 0.39928237  0.44257641]] \n",
      " [[-0.29996071  0.31544102]]\n",
      "Iter [ 98 ] Error: [[  6.58700387e-07]]\n",
      "l2_delta= [[-0.00028694]]\n",
      "[[ 0.09930726  0.64255023]\n",
      " [ 0.39930726  0.44255023]] \n",
      " [[-0.30014683  0.31525986]]\n",
      "Iter [ 99 ] Error: [[  5.92944818e-07]]\n",
      "l2_delta= [[-0.00027225]]\n",
      "[[ 0.0993309  0.6425254]\n",
      " [ 0.3993309  0.4425254]] \n",
      " [[-0.30032342  0.31508797]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x, deriv=False):\n",
    "  if (deriv == True):\n",
    "    return x * (1 - x) #如果deriv为true，求导数\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X = np.array([[0.35],[0.9]]) #输入层\n",
    "y = np.array([[0.5]]) #输出值\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "W0 = np.array([[0.1,0.8],[0.4,0.6]])\n",
    "W1 = np.array([[0.3,0.9]])\n",
    "print('original ', W0, '\\n', W1)\n",
    "\n",
    "for j in range(100):\n",
    "  l0 = X #相当于文章中x0\n",
    "  l1 = nonlin(np.dot(W0,l0)) #相当于文章中y1\n",
    "  l2 = nonlin(np.dot(W1,l1)) #相当于文章中y2\n",
    "  l2_error = y - l2\n",
    "  Error = 1 / 2.0 * (y - l2) ** 2\n",
    "  \n",
    "  print('Iter [', j, '] Error:', Error)\n",
    "  l2_delta = l2_error * nonlin(l2, deriv=True) #this will backpack\n",
    "\n",
    "  print('l2_delta=', l2_delta)\n",
    "  l1_error = l2_delta*W1; #反向传播\n",
    "  l1_delta = l1_error * nonlin(l1, deriv=True)\n",
    "\n",
    "  W1 += l2_delta * l1.T; #修改权值\n",
    "  W0 += l0.T.dot(l1_delta)\n",
    "  print(W0, '\\n', W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[A Neural Network in 11 lines of Python (Part 1)](https://iamtrask.github.io/2015/07/12/basic-python-network/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: A Tiny Toy Network\n",
    "\n",
    "\n",
    "| Inputs | Output\n",
    "| :---: | :---:\n",
    "| 0 0 1 | 0\n",
    "| 1 1 1 | 1\n",
    "| 1 0 1 | 1\n",
    "| 0 1 1 | 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original  [[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]] \n",
      " [[-0.30032342  0.31508797]]\n",
      "Output After Training:\n",
      "[[ 0.11035029]\n",
      " [ 0.09193919]\n",
      " [ 0.92564882]\n",
      " [ 0.91041229]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x, deriv=False):\n",
    "  if (deriv == True):\n",
    "    return x * (1 - x) #如果deriv为true，求导数\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#输入层\n",
    "X = np.array([ [0, 0, 1],\n",
    "               [0, 1, 1],\n",
    "               [1, 0, 1],\n",
    "               [1, 1, 1] ])\n",
    "\n",
    "#输出值\n",
    "y = np.array([[0, 0, 1, 1]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# w0\n",
    "W0 = 2 * np.random.random((3, 1)) - 1\n",
    "print('original ', W0, '\\n', W1)\n",
    "\n",
    "for j in range(100):\n",
    "  l0 = X #相当于文章中x0\n",
    "  l1 = nonlin(np.dot(l0, W0)) #相当于文章中y1\n",
    "\n",
    "  l1_error = y - l1\n",
    "  # print('Iter [', j, '] l1_error:', l1_error)\n",
    " \n",
    "  l1_delta = l1_error * nonlin(l1, deriv=True) #this will backpack\n",
    "  # print('l1_delta=', l1_delta)\n",
    "\n",
    "  W0 += l0.T.dot(l1_delta)\n",
    "\n",
    "  # print(W0, '\\n', W1)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: A Slightly Harder Problem\n",
    "\n",
    "### 2.1 横向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.496410031903\n",
      "Error:0.00858452565325\n",
      "Error:0.00578945986251\n",
      "Error:0.00462917677677\n",
      "Error:0.00395876528027\n",
      "Error:0.00351012256786\n",
      "Output After Training:\n",
      "[[  7.26191199e-01   1.16411907e-01   9.26183940e-01   9.97110310e-01]\n",
      " [  1.66762801e-01   3.92990161e-04   1.66519465e-02   8.96576847e-01]\n",
      " [  9.96229372e-01   8.95211165e-01   2.23120442e-02   8.38385421e-01]\n",
      " [  9.52239003e-01   2.48589483e-02   3.07990327e-05   1.15301801e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "  if(deriv==True):\n",
    "    return x*(1-x)\n",
    "  return 1/(1+np.exp(-x))\n",
    "    \n",
    "X = np.array([ [0,0,1],\n",
    "               [0,1,1],\n",
    "               [1,0,1],\n",
    "               [1,1,1] ])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2 * np.random.random((3, 4)) - 1\n",
    "syn1 = 2 * np.random.random((4, 1)) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "  # Feed forward through layers 0, 1, and 2\n",
    "  l0 = X\n",
    "  l1 = nonlin(np.dot(l0,syn0))\n",
    "  l2 = nonlin(np.dot(l1,syn1))\n",
    "\n",
    "  # how much did we miss the target value?\n",
    "  l2_error = y - l2\n",
    "    \n",
    "  if (j % 10000) == 0:\n",
    "    print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
    "\n",
    "  # in what direction is the target value?\n",
    "  # were we really sure? if so, don't change too much.\n",
    "  l2_delta = l2_error * nonlin(l2, deriv=True)\n",
    "\n",
    "  # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "  l1_error = l2_delta.dot(syn1.T)\n",
    "\n",
    "  # in what direction is the target l1?\n",
    "  # were we really sure? if so, don't change too much.\n",
    "  l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "  syn1 += l1.T.dot(l2_delta)\n",
    "  syn0 += l0.T.dot(l1_delta)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 纵向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.500620808426\n",
      "Error:0.499839521357\n",
      "Error:0.499908550766\n",
      "Error:0.499934552293\n",
      "Error:0.499948496145\n",
      "Error:0.499957282198\n",
      "Output After Training:\n",
      "[[  6.48054319e-05   9.34988367e-06   8.02275630e-06   1.15743682e-06]\n",
      " [  6.84963854e-05   7.15849782e-06   7.84953640e-06   8.20303686e-07]\n",
      " [  6.93700693e-05   7.54067793e-06   6.87512696e-06   7.47299676e-07]\n",
      " [  6.87538652e-05   7.17287805e-06   7.66880121e-06   8.00018532e-07]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "  if(deriv==True):\n",
    "    return x*(1-x)\n",
    "  return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([ [0,0,1],\n",
    "               [0,1,1],\n",
    "               [1,0,1],\n",
    "               [1,1,1] ]).T\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2 * np.random.random((4, 3)) - 1\n",
    "syn1 = 2 * np.random.random((1, 4)) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "  # Feed forward through layers 0, 1, and 2\n",
    "  l0 = X\n",
    "  l1 = nonlin(np.dot(syn0, l0))\n",
    "  l2 = nonlin(np.dot(syn1, l1))\n",
    "\n",
    "  # how much did we miss the target value?\n",
    "  l2_error = y - l2\n",
    "    \n",
    "  if (j % 10000) == 0:\n",
    "    print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
    "\n",
    "  # in what direction is the target value?\n",
    "  # were we really sure? if so, don't change too much.\n",
    "  l2_delta = l2_error * nonlin(l2, deriv=True)\n",
    "\n",
    "  # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "  l1_error = l2_delta.dot(syn1.T)\n",
    "\n",
    "  # in what direction is the target l1?\n",
    "  # were we really sure? if so, don't change too much.\n",
    "  l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "  # syn1 += l1.T.dot(l2_delta)\n",
    "  # syn0 += l0.T.dot(l1_delta)\n",
    "  syn1 += l2_delta.dot(l1.T)\n",
    "  syn0 += l1_delta.dot(l0.T)\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "print(l1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
